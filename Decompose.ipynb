{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de15f746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from docx import Document\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9322da94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta prompt loaded: v0.3-2025-10-16 ba2b73c44d3a\n"
     ]
    }
   ],
   "source": [
    "# === Meta Prompt (single cell) ===========================================\n",
    "from textwrap import dedent\n",
    "import hashlib\n",
    "\n",
    "META_PROMPT_VERSION = \"v0.3-2025-10-16\"   \n",
    "MAX_EMBED_WORDS    = 25                   \n",
    "STRICT_JSON_NOTICE = \"Return STRICT JSON only (no markdown).\"\n",
    "\n",
    "META_PROMPT = dedent(f\"\"\"\n",
    "SYSTEM:\n",
    "You analyze a multi-party conversation turn by turn.\n",
    "For EACH turn, output one JSON object describing that speaker's\n",
    "meaningful position content, following this exact schema:\n",
    "\n",
    "{{\n",
    "    \"Position (full)\": \"<one-sentence summary of the speaker's main claim, if any>\",\n",
    "    \"Sub-positions\": [\n",
    "        \"<atomic idea 1>\",\n",
    "        \"<atomic idea 2>\",\n",
    "        \"<atomic idea 3>\"\n",
    "    ],\n",
    "    \"Embedding Units\": [\n",
    "        {{\n",
    "            \"unit\": \"<atomic idea 1>\",\n",
    "            \"type\": \"sub-position\"\n",
    "        }},\n",
    "        {{\n",
    "            \"unit\": \"<atomic idea 2>\",\n",
    "            \"type\": \"sub-position\"\n",
    "        }}\n",
    "    ],\n",
    "    \"HasContent\": true/false,\n",
    "    \"Focus Topic\": \"<main topic or issue discussed, or null if no content>\",\n",
    "    \"Rationale\": \"<= MAX_EMBED_WORDS explanation of how the sub-positions were derived>\"\n",
    "}}\n",
    "\n",
    "CONTENT RULES:\n",
    "1. **Extract only meaningful opinion content.**\n",
    "    If the turn consists of small talk, acknowledgments, procedural comments, \n",
    "    or filler (e.g., “anything else?”, “okay”, “cool”, “yeah”, “go ahead”), then:\n",
    "        - \"HasContent\": false\n",
    "        - \"Sub-positions\": []\n",
    "        - \"Position (full)\": \"\"\n",
    "        - \"Embedding Units\": []\n",
    "        - \"Focus Topic\": null\n",
    "        - Provide a brief Rationale explaining why no content was found.\n",
    "\n",
    "2. **For content-bearing turns:**\n",
    "    - Identify the speaker's main claim as “Position (full)”.\n",
    "    - Extract **1-3 sub-positions** representing atomic ideas.\n",
    "    - Each sub-position must be an independent, simple, embedding-friendly\n",
    "        sentence expressing exactly **one** idea.\n",
    "    - Avoid connectors (\"and\", \"but\", \"because\") inside sub-positions.\n",
    "    - Sub-positions must correspond directly to clauses or reasoning in the turn.\n",
    "\n",
    "3. **Do NOT attempt to determine whether the speaker's position changed**\n",
    "    relative to previous turns. Just analyze this turn alone.\n",
    "\n",
    "4. **Coherence and Neutrality:**\n",
    "    - Use neutral, non-speculative language.\n",
    "    - Summaries must reflect the content of the turn accurately.\n",
    "\n",
    "OUTPUT RULES:\n",
    "1. Output a JSON array (list), one object per turn.\n",
    "2. Strictly valid JSON only — no markdown, no comments, no trailing commas.\n",
    "3. “Embedding Units” must repeat the sub-positions exactly (no paraphrasing).\n",
    "4. If “HasContent” is false, fields describing content must be empty or null.\n",
    "\n",
    "INPUT YOU WILL RECEIVE NEXT:\n",
    "- The full conversation transcript with labeled speakers.\n",
    "\n",
    "\"\"\").strip()\n",
    "\n",
    "META_PROMPT_HASH = hashlib.sha256(META_PROMPT.encode(\"utf-8\")).hexdigest()[:12]\n",
    "print(\"Meta prompt loaded:\", META_PROMPT_VERSION, META_PROMPT_HASH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77644552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x7b83d93a3f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3fc0a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    \"\"\"Read a .docx file and return a list of non-empty lines.\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    lines = []\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text:\n",
    "            lines.append(text)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2aeba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transcript(lines):\n",
    "    data = []\n",
    "    turn_id = 1\n",
    "    current_speaker = None\n",
    "    current_text = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        \n",
    "        # Identify section headers \"Task x:\" and skip them\n",
    "        if re.match(r\"(?i)^Task\\s*\\d+\", line):\n",
    "            continue\n",
    "        \n",
    "        # Identify the speaker\n",
    "        match = re.match(r\"^(P\\d+):\\s*(.*)\", line)\n",
    "        # match = re.match(r\"^()\", line)\n",
    "        if match:\n",
    "            speaker = match.group(1)\n",
    "            text = match.group(2)\n",
    "            \n",
    "            # If the same speaker continues, aoppend the text\n",
    "            # P1: Hello.\n",
    "            # P1: I think ...\n",
    "            if speaker == current_speaker:\n",
    "                current_text += \" \" + text\n",
    "            # P1: Hello.\n",
    "            # P2: Hi. \n",
    "            else: \n",
    "                if current_speaker is not None:       \n",
    "                    data.append({\n",
    "                        \"Position ID\": turn_id,\n",
    "                        \"Speaker\": current_speaker,\n",
    "                        \"Text\": current_text.strip()\n",
    "                    })\n",
    "                    turn_id += 1\n",
    "            \n",
    "            current_speaker = speaker\n",
    "            current_text = text\n",
    "\n",
    "        # P1: Hello.\n",
    "        # I think ...\n",
    "        else:\n",
    "            current_text += \" \" + line\n",
    "        \n",
    "    # Append the last turn if exists\n",
    "    if current_speaker is not None:\n",
    "        data.append({\n",
    "            \"Position ID\": turn_id,\n",
    "            \"Speaker\": current_speaker,\n",
    "            \"Text\": current_text.strip()\n",
    "        })\n",
    "            \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_position(df, starting_positions, meta_prompt):\n",
    "    current_positions = starting_positions.copy()\n",
    "    results = []\n",
    "    \n",
    "    for i, row in tqdm(df.iterrows(), total = len(df)):\n",
    "        if i == 0:\n",
    "            positions = \"Starting positions:\\n\" + \"\\n\".join([f\"{p}: {pos}\" for p, pos in current_positions.items()])\n",
    "        else:\n",
    "            positions = \"Current known positions:\\n\" + \"\\n\".join([f\"{p}: {pos}\" for p, pos in current_positions.items()])\n",
    "        # Gather context, at most 5 previous turns would be included. If less than 5, then include all previous turns.\n",
    "        context = \"\\n\".join([\n",
    "            f\"{df.iloc[j]['Speaker']} (ID: {df.iloc[j]['Position ID']}): {df.iloc[j]['Text']}\"\n",
    "            for j in range(max(0, i-5), i+1)\n",
    "        ])\n",
    "    \n",
    "        prompt = f\"\"\"\n",
    "        Here is the known positions of all speakers:\n",
    "        {positions}\n",
    "        \n",
    "        Here is the conversation context so far:\n",
    "        {context}\n",
    "        \n",
    "        Current turn to analyze: \n",
    "        Speaker: {row['Speaker']} \n",
    "        ID: {row['Position ID']} \n",
    "        Text: \"{row['Text']}\"\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = client.responses.create(\n",
    "                model=\"gpt-4o-mini\",    # Not quite sure if we should use gpt-4o-mini or gpt-4o\n",
    "                                        # But seems that gpt-4o is tooooooo expensive))\n",
    "                instructions = meta_prompt,      # Like system prompt\n",
    "                input = prompt,         # Like user prompt\n",
    "                temperature = 0\n",
    "            )\n",
    "            text = response.output_text\n",
    "            text = re.sub(r'```(json)?', '', text).strip() # Prevent the possible markdown code block formatting. \n",
    "            # parsed = json.loads(text)\n",
    "            # current_positions[row['Speaker']] = parsed.get(\"Summary (embed)\", \"-\")\n",
    "            try:\n",
    "                parsed = json.loads(text)\n",
    "            except json.JSONDecodeError:\n",
    "                match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "                if match:\n",
    "                    parsed = json.loads(match.group(0))\n",
    "                else:\n",
    "                    raise ValueError(f\"Cannot parse model output: {text}\")\n",
    "\n",
    "            if isinstance(parsed, list):\n",
    "                if len(parsed) > 0 and isinstance(parsed[0], dict):\n",
    "                    parsed = parsed[0]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected list structure: {parsed}\")\n",
    "\n",
    "            current_positions[row['Speaker']] = parsed.get(\"Summary (embed)\", \"-\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            # print(f\"Error ID {row['Position ID']}: {e}\")\n",
    "            print(f\"\\n Error at ID {row['Position ID']}: {e}\")\n",
    "            print(\"---- Raw model output ----\")\n",
    "            print(text)\n",
    "            print(\"--------------------------\\n\")\n",
    "            parsed = {\"Position Change\": \"error\", \"New Position\": \"parse error\", \"Influenced by\": []}\n",
    "        results.append(parsed)\n",
    "        \n",
    "    new_df = pd.concat([df, pd.DataFrame(results)], axis=1)\n",
    "    # new_df = new_df.drop(columns = [\"Text\"])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd6b902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"S5_collective_cleaned.docx\"\n",
    "file_path = \"S10_mixed_cleaned.docx\"\n",
    "lines = read_docx(file_path)\n",
    "df = parse_transcript(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8bb6283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_positions = {\n",
    "    \"P1\": \"You would like the course to be about Cultural Understanding but are flexible about how that happens. \\\n",
    "            Your Worldview: You believe global citizenship begins with understanding - \\\n",
    "            you can't appreciate other cultures without deeply understanding it first.\",\n",
    "    \"P2\": \"You feel very strongly that teaching Intercultural Collaboration has to be a key aspect of this program. \\\n",
    "            You would like for students to be matched with international peers to work on shared challenges together. \\\n",
    "            Your Worldview: You believe real connection and understanding comes from working with others towards a shared goal. \\\n",
    "            Working together will also teach students to respect and value different perspectives and build real-world skills.\", \n",
    "    \"P3\": \"Your goal is to advocate for the course to teach systems-thinking. \\\n",
    "            You believe that helping students think of humanity as one big interconnected group is one of the most powerful ways \\\n",
    "            to foster global citizenship in a complex world. When students learn to recognize patterns, ripple effects, \\\n",
    "            and unintended consequences, they develop deeper empathy, critical thinking, and a sense of responsibility \\\n",
    "            that goes beyond surface-level cultural knowledge. Use simple but strong examples to make your point \\\n",
    "            and expand others' thinking about what global citizenship should mean.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5773bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [02:20<00:00,  3.79s/it]\n"
     ]
    }
   ],
   "source": [
    "output = analyze_position(df, starting_positions, META_PROMPT)\n",
    "output.to_csv(\"S10-M_position_analysis_1127_Strict_version.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
